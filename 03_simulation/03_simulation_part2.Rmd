---
title: "Part 2: Beta diversity = 1, Area = 2-8"
output: html_document
---

This is Part 2, where we aggregate plots so that beta diversity is maintained at 1 (i.e. all communities have the same sown species composition) and scale is increased 
  * this means manipulate scale without manipulating species compositions
  * the intended species compositions will be used and aggregated step-wise from 2-8 communities according to the original design
  
```{r Setup, results = FALSE} 

# include: whether to include anything from a code chunk in the output document --> when include = F, this whole chunk is excluded in the output!

knitr::opts_chunk$set(echo = TRUE)
# Sets the R markdown options so that the code is displayed in the final html file. If it is set to FALSE then the code isn't displayed only the result is 

rm(list=ls()) #clears my global environment 

# Load libraries
library(vegan) # calculate diversity metrics - without this package the Wang et al. Function does not work
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(knitr) # data manipulation

#load data
load("../01_data/02_temporary/sim_data_11sp.RData")


#load VariancePartitioning Function for the calculation of stability metrics
source("../02_functions/Wang_et_al_2019_VariancePartitioning.r")

options(stringsAsFactors = F)
#to make sure that all strings are treated as characters and not factors unless specified

```

# Step 1. Separate years and then species compositions so that we can subsample within them. 

```{r divide dataset into lists, results = FALSE}

sim_data_11sp$total.biomass<-rowSums(sim_data_11sp[,6:16]) #calculate total biomass for every row (i.e. sample)

year.id<-c(1:5) #create a vector containing all the years
comp.id<-factor(unique(sim_data_11sp$sown_species_comp)) #create a vector containing all the species compositions once
data.list.year<-lapply(year.id, function(x) sim_data_11sp[sim_data_11sp$year==x,]) #subset sim_data_11sp by years and store that data as lists in year.id with one list for each year --> data.list.year is a list of 4

#create a list of 4 (one list for each year), each containing a list of 43 (one list for each species composition)
data.list.comp<-vector(mode="list") # create an empty list to store data in for each species composition
for(i in year.id){ #for every year
  data.list.comp[[i]]=vector(mode="list", length=length(comp.id)) #create a list for all species compositions
  data.list.comp[[i]]<-lapply(comp.id, function(x) data.list.year[[i]][data.list.year[[i]]$sown_species_comp==x,]) # subset data by year and species composition
}

```

# Step 2. Retrieve Stability Metrics for all other areas (2-8) 
Sample without replacement - this allows to use all unique combinations of subplots for each species composition and area

```{r beta_div1 & Area2-8, results = FALSE}

load("../01_data/02_temporary/stability_data_scale1_11sp.RData")

# create a list of 8 to store data for each area
Areas_unique_11sp <- list(1:8)
Areas_unique_11sp[[1]] <-  subset(stability_data_scale1_11sp, select = -19) # add data for community stability to list without last column to maintain dimensions


for (A in 2:8){ # for areas 2-8 --> we don't want to loop through Area=1 as that is the community scale 
  
  ### Step 1: sub-sample Area using data.list.comp  ############################
  
  # make empty dataframe so we can store the data that we need 
  plotIDs.scale_area<-vector(mode="list", length=length(comp.id))
  scale_area<-data.frame(year=numeric(), div=numeric(), unique_ID=character(), compID=character(), sampleID=numeric(), an=numeric(), ar=numeric(),
                         lu=numeric(), or=numeric(), po=numeric(), tr=numeric(), ve=numeric(), fe=numeric(), ru=numeric(), ho=numeric(), kn=numeric(), 
                         total.biomass=numeric())
  
  # calculate number of unique combinations possible for a given landscape size:
  # P(n,r) = n!/r!(n-r)!, where n = 8 as we have a total of 8 communities to choose from and n = A as we select A subplots to create a landscape of area A
  resamplings <- factorial(8)/(factorial(A)*factorial(8-A)) 
  
  # create a dataset containing all data of interest for all unique combinations of A plots for a given species composition
  # loop through each species composition for the first year
  for (j in 1:43){ 
    
    plotIDs.scale_area[[j]]<-matrix(nrow=resamplings, ncol=A+1) # for each species composition, create an empty matrix to store unique combinations
    
    # fill that matrix
    if (length(data.list.comp[[1]][[j]]$unique_ID) == 8) { # tests if each species compositions has 8 unique plots --> this is needed because plot 54c is missing
      recombinations <- combn(data.list.comp[[1]][[j]]$unique_ID,A,FUN = NULL, simplify = TRUE) #create all possible unique combinations and store in a matrix/array
      recombinations <- t(recombinations) # transpose the matrix so that it is in a long format
      counter <- ((j-1) * resamplings) + 1:resamplings # makes sure that each combination of each species composition has a unique count
      recombinations <- cbind(recombinations, counter) # combine 
      plotIDs.scale_area[[j]] <- recombinations # assigns such a matrix to each species composition
      
      
      # loop through each unique combination
      for(i in 1:resamplings){ 
        
        # create a sample containing only the combination of row i from the matrix of all possible combinations
        year1scale_area <- plotIDs.scale_area[[j]][i,1:A] 
        # by setting replace = F  the same subplot is not sampled A times in the same sample
        # setting replace = F increases the nrows of the final dataframes in Areas[[A]]
        # but it also seems to be problematic for A=8 
        ## --> I think that is because for comp.id "ca" there are only 7 unique_id's and therefore sample size (A) > population 
        ##(data.list.comp[[1]][[j]]$unique_ID)
        
        if (A==2) {
          # create a temporary data set that has only the subplots we sampled:
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2],]
          # aggregate the data so that we have the summed biomass across our two subplots:
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id:
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
          #this is repeated for all other areas areas; 
          #as the number of areas is increased the number of times we need to ask if species compositions are the same also has to be increased
        } else if (A==3) {
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3],] 
          # aggregate the data so that we have the summed biomass across our two subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id 
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
        } else if (A==4) {
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[4],]     
          # aggregate the data so that we have the summed biomass across our two subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id 
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
        } else if (A==5) {
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[4]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[5],]                                                                                
          # aggregate the data so that we have the summed biomass across our sampled subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id  
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1])
        } else if (A==6) {
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[4]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[5]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[6],]                       
          # aggregate the data so that we have the summed biomass across our two subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id 
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
        } else if (A==7) {
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[4]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[5]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[6]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[7],]                                                                                
          # aggregate the data so that we have the summed biomass across our two subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id 
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
        } else if (A==8) { 
          # create a temporary data set that has only the subplots we sampled 
          temp<-data.list.comp[[1]][[j]][data.list.comp[[1]][[j]]$unique_ID==year1scale_area[1]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[2]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[3]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[4]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[5]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[6]
                                         |data.list.comp[[1]][[j]]$unique_ID==year1scale_area[7]|data.list.comp[[1]][[j]]$unique_ID==year1scale_area[8],]                         
          # aggregate the data so that we have the summed biomass across our two subplots  
         scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
          # give each sample a unique sample id  
          scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) 
        }
        # add our new data from this run of the loop to the last data
        scale_area<-rbind(scale_area,scale_area.temp)
      } 
    }
  }
  
  ### Step 2: Take the same plots for all other years ##########################
  
  for (k in 2:5){ # loops across the remaing years
    for(j in 1:43){ # loops across our species compositions
      for(i in 1:resamplings){ # loops across our resamplings
        if (!is.na(plotIDs.scale_area[[j]][i])){ # tests that there is not a NA for the subplot combination 
          #--> if there were not A subplots, NAs were inserted at plotIDs.scale_area[[j]]
          
          if (A==2) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2],]
            
            
          } else if (A==3) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3],] 
            
          } else if (A==4) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,4],]
            
          } else if (A==5) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,4]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,5],]
            
          } else if (A==6) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,4]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,5]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,6],]
            
          } else if (A==7) {
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,4]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,5]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,6]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,7],] 
            
          } else if (A==8){
            
            temp<-data.list.comp[[k]][[j]][data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,1]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,2]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,3]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,4]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,5]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,6]
                                           |data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,7]|data.list.comp[[k]][[j]]$unique_ID==plotIDs.scale_area[[j]][i,8],]  
          }
          
          
          if(length(temp$total.biomass)>0){ # tests if data is present since some species combinations are gone in years 2 and 3
           scale_area.temp<-aggregate(total.biomass~year+div+unique_ID+sown_species_comp+an+ar+lu+or+po+tr+ve+fe+ru+ho+kn, data=temp, FUN=sum)
            scale_area.temp$sampleID<-as.numeric(plotIDs.scale_area[[j]][i,A+1]) # adds in our same sample ids so we can pretend the combinations are basically plots                     themselves
            # adds our new data from this run of the loop to the last data
            scale_area<-rbind(scale_area,scale_area.temp) # adds the new data to the old data
          }
        } 
      }
    }
  }
  
### Step 3: calculate Variability metrics ######################################
  
  # create new dataframe to store stability metrics per scale
variability_data_scale_area <- data.frame(sampleID=numeric(), CompID=character(), div=numeric(), Species_var=numeric(), Alpha_var=numeric(),  
                                          Metapopulation_var=numeric(),  Gamma_var=numeric(), Pop_synch=numeric(), Spatial_synch=numeric(), 
                                          Species_synch=numeric(), Metapopulation_synch=numeric(), avg_richness=numeric(), A_Invsimpson=numeric(), Beta_div=numeric(), 
                                          B_Invsimpson=numeric(), temp_mean=numeric(), temp_sd=numeric())
  ## species_var == species variability or population variability
  ## these are all variability metrics --> stability is the inverse of variability
 
  #for every landscape (=unique sample id):
  for (i in 1:length(unique(scale_area$sampleID))){ 
   
    datax = scale_area[scale_area$sampleID==i,] # selects a subset from scale_area data --> this subset contains rows only for sample i
    
    if(nrow(datax)==(A*5)){ # tests if there is data for all years, because some subplots only have data for one or two years 
      # create a temporary dataset to store selected information with
      temp <- datax[1,c("sampleID", "sown_species_comp", "div")]
      
      TH.year = 5      ### the number of years to be used 
      TH.plot = A      ### for the number of communities --> = area size
      
      arrayx = array(NA,dim=c(ncol(datax)-6,TH.year,TH.plot)) # -7 to take only the abundance per species data 
      # datax has 17 columns in total --> 17 - 6 = 11 -->here we use 11 species of BioCliVE
      # arrayx creates a multi-dimensional array of NA's
      ## the number of communities (TH.plot) gives the number of dimensions - when TH.plot = 2 (at scale 2 the number of communities is 2), then there will be 2 matrices
      ### for each community a matrix is created with 11 rows (1 for each species) and 4 columns (1 for each year)
      
      # fill in this array based on datax, by community and by year
      plotindex = sort(unique(datax$unique_ID))
      yearindex = sort(unique(datax$year))
      
      for(i in 1:TH.plot) #to loop across the matrices (#TH.plot) 
        for(j in 1:TH.year){ #to loop through the years
          tmpdata = datax[datax$unique_ID==plotindex[i] & datax$year==yearindex[j],-c(1:4,16:17)] 
          # -c(1:4,16:17) makes sure that those columns are disregarded as they do not contain biomass data across years for the individual species
          arrayx[,j,i] = unlist(tmpdata) 
        }
      
      # Now the variance partitioning function can be applied to this array to obtain the desired variability metrics
      var_part_result = var.partition(arrayx) #var.partition after Wang et al. 2019
      
      # extract metrics of interest
         my_metrics <- var_part_result[c(1:9,11,14:17)]
      
      # store these metrics in a temporary dataframe 
      variability_temp <- t(as.data.frame(my_metrics))
      
      # combine the temporary dataframes to resemble the structure of the empty dataframe created above
      temp <- cbind(temp,variability_temp)
      
      # add new data from this loop to the last data
      variability_data_scale_area <- rbind(variability_data_scale_area,temp)
      
    }
  }
  
  # add Area and rearrange
  variability_data_scale_area$Areasize <- as.numeric(rep(A, nrow(variability_data_scale_area)))
  variability_data_scale_area <-variability_data_scale_area[,c(18,1:17)]
  
  # change column names 
  colnames(variability_data_scale_area) <- c("Area", "sampleID", "CompID", "div", "Species_var", "Alpha_var",  "Metapopulation_var",  "Gamma_var", "Pop_synch", "Spatial_synch", "Species_synch", "Metapopulation_synch", "avg_richness", "Alpha_InvSimpson", "Beta_div", "Beta_InvSimpson", "temp_mean", "temp_sd")

  # convert variability to stability
  stability_conversion <- apply(variability_data_scale_area[,5:12],c(1,2), function(x) 1/x) # stability is the inverse of variability
  colnames(stability_conversion) <- c("Species_stab","Alpha_stab","Metapopulation_stab","Gamma_stab","Pop_AS","Spatial_AS","Species_AS","Metapopulation_AS")
  stability_data_Area_A <- cbind(variability_data_scale_area[,1:4],stability_conversion,variability_data_scale_area[,13:18])

  
  ### store data for Area of size A in Areas[[A]]  #############################
  
  Areas_unique_11sp[[A]] <- stability_data_Area_A
}

```

```{r merge, results=FALSE}
#collapse list into 1 dataset
Beta1_ScaleManipulation_unique_11sp <- do.call("rbind", Areas_unique_11sp)

#add a column indicating the intended Beta diversity level for my own reference
Beta1_ScaleManipulation_unique_11sp$Intended_BetaDiv <- as.numeric(rep(1, nrow(Beta1_ScaleManipulation_unique_11sp)))
```

# Save data

```{r save, results = FALSE}

# save as .RData so that it is easier to re-use (ORIGINAL)
save(Beta1_ScaleManipulation_unique_11sp, file = "../01_data/02_temporary/beta1_ScaleManipulation_unique_11sp.RData")

```



